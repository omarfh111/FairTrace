"""
Regulation Agent - Banking Regulation Expert (Agentic Version)

This agent answers questions about banking regulations with:
1. Agentic retry loop with query reformulation
2. Quality assessment of retrieval results
3. Citation-aware responses with article references
4. Multi-turn conversation context

Uses the reg_bancaire.pdf (Tunisian Banking Regulation) as knowledge base.
"""

import json
import sys
from pathlib import Path
from typing import Optional

sys.path.insert(0, str(Path(__file__).parent.parent))

from agents.base_agent import BaseAgent
from tools.qdrant_retriever import (
    search_regulations,
    format_regulation_results,
    embed_query
)


# Agentic configuration
MAX_RETRIEVAL_ATTEMPTS = 3
MIN_RELEVANCE_SCORE = 0.03  # Minimum RRF score to consider relevant
MIN_RELEVANT_DOCS = 2  # Need at least 2 relevant docs


class RegulationAgent(BaseAgent):
    """Banking Regulation Expert - Agentic RAG with retry and reformulation."""
    
    def __init__(self):
        super().__init__(
            name="RegulationAgent",
            role_description="Expert in Tunisian banking regulations (RÃ©glementation Bancaire BCT)"
        )
        self.conversation_history: list[dict] = []
        self.max_history = 5  # Keep last 5 exchanges for context
    
    @property
    def system_prompt(self) -> str:
        return """Tu es un expert juridique en rÃ©glementation bancaire tunisienne (BCT - Banque Centrale de Tunisie).

## Ta Mission
Fournir des rÃ©ponses prÃ©cises et bien structurÃ©es sur la rÃ©glementation bancaire en te basant UNIQUEMENT sur les documents fournis.

## RÃ¨gles Strictes
1. **Langue**: RÃ©ponds en franÃ§ais (sauf si question en anglais)
2. **Citations obligatoires**: Chaque affirmation DOIT Ãªtre suivie d'une citation [Article X, Page Y]
3. **FidÃ©litÃ©**: Ne JAMAIS inventer ou extrapoler - reste fidÃ¨le aux documents
4. **ClartÃ©**: Utilise des listes Ã  puces et sous-titres pour structurer
5. **ComplÃ©tude**: Couvre TOUS les aspects de la question mentionnÃ©s dans les documents

## Format de Citation
- Pour les articles: [Article 5, Page 42]
- Pour les circulaires: [Circulaire nÂ°2006-11, Page 158]
- Pour les notes: [Note aux banques du 15/01/2020, Page 89]

## Exemple de Bonne RÃ©ponse
Question: "Quels sont les objectifs de la Banque centrale?"

RÃ©ponse:
**Les objectifs de la Banque centrale de Tunisie sont:**

1. **StabilitÃ© des prix** - Maintenir la stabilitÃ© monÃ©taire et maÃ®triser l'inflation [Article 7, Page 15]

2. **StabilitÃ© financiÃ¨re** - Assurer la soliditÃ© du systÃ¨me bancaire et prÃ©venir les risques systÃ©miques [Article 8, Page 16]

3. **Politique de change** - GÃ©rer les rÃ©serves de change et la politique monÃ©taire [Article 10, Page 18]

## Format JSON de RÃ©ponse
{
    "answer": "RÃ©ponse structurÃ©e avec citations [Article X, Page Y] Ã  chaque affirmation clÃ©",
    "citations": [
        {"article": "Article 7", "page": 15, "excerpt": "Extrait exact du texte..."}
    ],
    "confidence": "HIGH" | "MEDIUM" | "LOW",
    "follow_up_questions": ["Question pertinente 1?", "Question pertinente 2?"]
}

## Si Information Non TrouvÃ©e
{
    "answer": "Les documents consultÃ©s ne contiennent pas d'information spÃ©cifique sur [sujet]. Cependant, les articles suivants pourraient Ãªtre pertinents: [suggestions]",
    "citations": [],
    "confidence": "LOW",
    "follow_up_questions": ["Questions alternatives..."]
}"""

    @property
    def reformulation_prompt(self) -> str:
        return """Tu es un assistant spÃ©cialisÃ© dans la reformulation de requÃªtes de recherche.

L'utilisateur a posÃ© une question sur la rÃ©glementation bancaire tunisienne, mais les rÃ©sultats 
de recherche ne sont pas satisfaisants.

Ta tÃ¢che: Reformuler la question pour amÃ©liorer les rÃ©sultats de recherche.

StratÃ©gies de reformulation:
1. Utiliser des synonymes ou termes techniques bancaires
2. DÃ©composer la question en concepts clÃ©s
3. Ajouter le contexte rÃ©glementaire (BCT, loi bancaire, circulaire)
4. Traduire les termes anglais en franÃ§ais si nÃ©cessaire

RÃ©ponds UNIQUEMENT avec la nouvelle requÃªte reformulÃ©e, sans explication.
Limite: 100 mots maximum."""
    
    def _assess_retrieval_quality(self, results: list[dict]) -> tuple[bool, str]:
        """
        Assess quality of retrieval results.
        
        Returns:
            (is_good_quality, reason)
        """
        if not results:
            return False, "no_results"
        
        # Count documents with good relevance scores
        relevant_docs = [r for r in results if r.get("score", 0) >= MIN_RELEVANCE_SCORE]
        
        if len(relevant_docs) < MIN_RELEVANT_DOCS:
            return False, f"low_relevance: only {len(relevant_docs)} relevant docs"
        
        # Check if top result has good score
        top_score = results[0].get("score", 0)
        if top_score < MIN_RELEVANCE_SCORE * 1.5:
            return False, f"weak_top_result: score={top_score:.3f}"
        
        return True, "good"
    
    def _reformulate_query(self, original_query: str, attempt: int, previous_queries: list[str]) -> str:
        """
        Use LLM to reformulate query for better retrieval.
        """
        strategies = [
            "Ajoute des termes techniques bancaires ou rÃ©glementaires.",
            "Simplifie la question en mots-clÃ©s essentiels.",
            "Reformule en utilisant des synonymes et le vocabulaire BCT."
        ]
        
        strategy = strategies[min(attempt - 1, len(strategies) - 1)]
        
        messages = [
            {"role": "system", "content": self.reformulation_prompt},
            {"role": "user", "content": f"""Question originale: {original_query}

RequÃªtes dÃ©jÃ  essayÃ©es: {previous_queries}

StratÃ©gie Ã  appliquer: {strategy}

Donne une nouvelle formulation de la question:"""}
        ]
        
        try:
            reformulated = self._call_llm(messages).strip()
            # Clean up - remove quotes if present
            reformulated = reformulated.strip('"\'')
            # Limit length
            if len(reformulated) > 300:
                reformulated = reformulated[:300]
            return reformulated
        except Exception as e:
            # Fallback: just add context
            return f"rÃ©glementation bancaire BCT {original_query}"
    
    def search_evidence(self, query: str, rerank: bool = False) -> list[dict]:
        """Search regulations collection for relevant chunks.
        
        Args:
            query: Search query text
            rerank: If True, use mxbai reranker for two-stage retrieval
        """
        # Compute embeddings once
        dense_vec, sparse_idx, sparse_vals = embed_query(query)
        
        # Search for relevant regulation chunks
        response = search_regulations(
            query_text=query,
            limit=8,  # Get top 8 most relevant chunks
            dense_vector=dense_vec,
            sparse_indices=sparse_idx,
            sparse_values=sparse_vals,
            rerank=rerank,
            rerank_top_k=24 if rerank else None  # 3x for reranking
        )
        
        return response.get("results", [])
    
    def search_with_retry(self, query: str, rerank: bool = False) -> tuple[list[dict], list[str], int]:
        """
        Agentic search with retry and query reformulation.
        
        Args:
            query: Search query text
            rerank: If True, use mxbai reranker for two-stage retrieval
        
        Returns:
            (results, queries_tried, attempt_count)
        """
        queries_tried = [query]
        current_query = query
        
        for attempt in range(1, MAX_RETRIEVAL_ATTEMPTS + 1):
            # Search with current query
            results = self.search_evidence(current_query, rerank=rerank)
            
            # Assess quality
            is_good, reason = self._assess_retrieval_quality(results)
            
            if is_good:
                # Good results - return them
                return results, queries_tried, attempt
            
            # Bad results - try reformulation if we have attempts left
            if attempt < MAX_RETRIEVAL_ATTEMPTS:
                print(f"âš ï¸ Attempt {attempt}: {reason} - reformulating query...")
                current_query = self._reformulate_query(query, attempt, queries_tried)
                queries_tried.append(current_query)
                print(f"   New query: {current_query[:80]}...")
            else:
                # Last attempt - return what we have
                print(f"âš ï¸ Attempt {attempt}: {reason} - returning best results")
        
        return results, queries_tried, MAX_RETRIEVAL_ATTEMPTS
    
    def analyze(self, query: str, evidence: list[dict], retrieval_attempts: int = 1) -> dict:
        """Analyze query with evidence and generate citation-aware response."""
        # Format evidence for LLM
        evidence_text = self._format_regulation_evidence(evidence)
        
        # Build conversation context
        context = self._build_conversation_context()
        
        messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": f"""Documents de rÃ©fÃ©rence:

{evidence_text}

{context}Question actuelle: {query}

RÃ©ponds en JSON avec les citations appropriÃ©es."""}
        ]
        
        response = self._call_llm_json(messages)
        
        try:
            result = json.loads(response)
            result["agent_name"] = self.name
            result["sources_count"] = len(evidence)
            result["retrieval_attempts"] = retrieval_attempts
            
            # Extract unique pages for reference
            pages = list(set(
                e.get("payload", {}).get("page_number") 
                for e in evidence 
                if e.get("payload", {}).get("page_number")
            ))
            result["source_pages"] = sorted(pages)[:5]  # Top 5 pages
            
            # Adjust confidence based on retrieval quality
            if retrieval_attempts > 1:
                # Lower confidence if we needed retries
                if result.get("confidence") == "HIGH":
                    result["confidence"] = "MEDIUM"
            
        except json.JSONDecodeError:
            result = {
                "agent_name": self.name,
                "answer": response,
                "citations": [],
                "confidence": "MEDIUM",
                "follow_up_questions": [],
                "sources_count": len(evidence),
                "source_pages": [],
                "retrieval_attempts": retrieval_attempts
            }
        
        return result
    
    def chat(self, message: str, conversation_id: Optional[str] = None, rerank: bool = False) -> dict:
        """
        Main chat interface with agentic retry loop.
        
        The agent will:
        1. Search for evidence
        2. Assess retrieval quality
        3. Reformulate query if results are poor (max 3 attempts)
        4. Generate citation-aware response
        
        Args:
            message: User's question
            conversation_id: Optional ID for conversation continuity
            rerank: If True, use mxbai reranker for two-stage retrieval
            
        Returns:
            Dict with answer, citations, suggestions, and retrieval metadata
        """
        # Agentic search with retry
        evidence, queries_tried, attempts = self.search_with_retry(message, rerank=rerank)
        
        # Generate response
        response = self.analyze(message, evidence, retrieval_attempts=attempts)
        
        # Add retrieval metadata
        response["queries_tried"] = queries_tried
        response["used_reformulation"] = len(queries_tried) > 1
        response["reranked"] = rerank
        
        # Update conversation history
        self.conversation_history.append({
            "role": "user",
            "content": message
        })
        self.conversation_history.append({
            "role": "assistant", 
            "content": response.get("answer", "")
        })
        
        # Trim history if too long
        if len(self.conversation_history) > self.max_history * 2:
            self.conversation_history = self.conversation_history[-self.max_history * 2:]
        
        return response
    
    def clear_history(self):
        """Clear conversation history."""
        self.conversation_history = []
    
    def _format_regulation_evidence(self, evidence: list[dict]) -> str:
        """Format regulation evidence for LLM consumption."""
        if not evidence:
            return "Aucun document pertinent trouvÃ©."
        
        lines = []
        for i, e in enumerate(evidence, 1):
            payload = e.get("payload", {})
            page = payload.get("page_number", "?")
            article = payload.get("article_ref", "")
            section = payload.get("section_title", "")
            content = payload.get("content", "")
            score = e.get("score", 0)
            
            header = f"[Document {i}] Page {page}"
            if article:
                header += f" - {article}"
            if section:
                header += f" ({section})"
            header += f" [Pertinence: {score:.2f}]"
            
            lines.append(f"{header}\n{content}\n")
        
        return "\n---\n".join(lines)
    
    def _build_conversation_context(self) -> str:
        """Build context from conversation history."""
        if not self.conversation_history:
            return ""
        
        context_lines = ["Historique de la conversation:"]
        for msg in self.conversation_history[-4:]:  # Last 2 exchanges
            role = "Utilisateur" if msg["role"] == "user" else "Assistant"
            content = msg["content"][:200] + "..." if len(msg["content"]) > 200 else msg["content"]
            context_lines.append(f"{role}: {content}")
        
        return "\n".join(context_lines) + "\n\n"
    
    def get_suggestions(self) -> list[str]:
        """Get contextual question suggestions."""
        if not self.conversation_history:
            # Initial suggestions
            return [
                "Quelles sont les obligations des banques en matiÃ¨re de conformitÃ©?",
                "Qu'est-ce que le ratio de solvabilitÃ© bancaire?",
                "Quelles sont les rÃ¨gles de gouvernance bancaire?",
                "Comment fonctionne le contrÃ´le interne dans les banques?",
                "Quelles sont les sanctions prÃ©vues par la BCT?"
            ]
        
        # Get suggestions from last response
        for msg in reversed(self.conversation_history):
            if msg["role"] == "assistant":
                # Try to parse as JSON to get follow_up_questions
                try:
                    parsed = json.loads(msg["content"])
                    if "follow_up_questions" in parsed:
                        return parsed["follow_up_questions"]
                except:
                    pass
                break
        
        # Default follow-up suggestions
        return [
            "Peux-tu prÃ©ciser ce point?",
            "Quels sont les articles connexes?",
            "Y a-t-il des exceptions Ã  cette rÃ¨gle?"
        ]


# Singleton instance for reuse
_regulation_agent: RegulationAgent | None = None


def get_regulation_agent() -> RegulationAgent:
    """Get or create RegulationAgent singleton."""
    global _regulation_agent
    if _regulation_agent is None:
        _regulation_agent = RegulationAgent()
    return _regulation_agent


# Test
if __name__ == "__main__":
    agent = RegulationAgent()
    
    print("Testing Agentic Regulation Agent...")
    print("=" * 60)
    
    # Test with a query that might need reformulation
    test_queries = [
        "Qu'est-ce que l'Article 5?",
        "What are the capital requirements?",  # English - should reformulate
        "comment fonctionne le KYC bancaire",  # Might need BCT context
    ]
    
    for query in test_queries[:1]:  # Just test first one
        print(f"\nğŸ“ Query: {query}")
        result = agent.chat(query)
        
        print(f"\nâœ… Answer: {result.get('answer', 'N/A')[:300]}...")
        print(f"ğŸ“Š Retrieval attempts: {result.get('retrieval_attempts', 1)}")
        print(f"ğŸ”„ Used reformulation: {result.get('used_reformulation', False)}")
        print(f"ğŸ“„ Queries tried: {result.get('queries_tried', [])}")
        print(f"ğŸ“– Source pages: {result.get('source_pages', [])}")
        print(f"â­ Confidence: {result.get('confidence', 'N/A')}")

